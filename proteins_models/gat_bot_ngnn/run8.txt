Using backend: pytorch
wandb: Currently logged in as: billywkli. Use `wandb login --relogin` to force relogin
device cuda:0
Loading data
Graph(num_nodes=132534, num_edges=79122504,
      ndata_schemes={'species': Scheme(shape=(1,), dtype=torch.int64), 'labels': Scheme(shape=(112,), dtype=torch.int64)}
      edata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32)})
wandb: wandb version 0.12.17 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /home/liweikai/gat_bot_ngnn/wandb/run-20220604_071703-1y1auh32
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-shadow-222
wandb: ‚≠êÔ∏è View project at https://wandb.ai/billywkli/GAT_BOT_NGNN_proteins
wandb: üöÄ View run at https://wandb.ai/billywkli/GAT_BOT_NGNN_proteins/runs/1y1auh32
Running 0
73084100 params
preprocess
Graph(num_nodes=132534, num_edges=79122504,
      ndata_schemes={'species': Scheme(shape=(1,), dtype=torch.int64), 'labels': Scheme(shape=(112,), dtype=torch.int64), 'feat': Scheme(shape=(8,), dtype=torch.float32), 'train_labels_onehot': Scheme(shape=(112,), dtype=torch.int64), 'deg': Scheme(shape=(), dtype=torch.float32)}
      edata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32)})
Epoch: 20/1800, Average epoch time: 22.32s, Loss: 0.2217
Train/Val/Test loss: 0.2912/0.4308/0.4105
Train/Val/Test/Best val/Final test score: 0.8588/0.8096/0.7739/0.8096/0.7739

Epoch: 40/1800, Average epoch time: 22.22s, Loss: 0.1985
Train/Val/Test loss: 0.3916/0.5528/0.5837
Train/Val/Test/Best val/Final test score: 0.8254/0.7578/0.7087/0.8392/0.7855

Epoch: 60/1800, Average epoch time: 22.12s, Loss: 0.1854
Train/Val/Test loss: 0.2201/0.3496/0.3242
Train/Val/Test/Best val/Final test score: 0.9194/0.8669/0.8265/0.8669/0.8265

Epoch: 80/1800, Average epoch time: 22.06s, Loss: 0.1758
Train/Val/Test loss: 0.2348/0.3729/0.3413
Train/Val/Test/Best val/Final test score: 0.9107/0.8514/0.8075/0.8833/0.8385

Epoch: 100/1800, Average epoch time: 22.07s, Loss: 0.1680
Train/Val/Test loss: 0.1766/0.3092/0.3117
Train/Val/Test/Best val/Final test score: 0.9405/0.8850/0.8475/0.8850/0.8475

Epoch: 120/1800, Average epoch time: 22.10s, Loss: 0.1622
Train/Val/Test loss: 0.2019/0.3438/0.3315
Train/Val/Test/Best val/Final test score: 0.9320/0.8724/0.8369/0.8850/0.8475

Epoch: 140/1800, Average epoch time: 22.14s, Loss: 0.1559
Train/Val/Test loss: 0.1831/0.3195/0.3206
Train/Val/Test/Best val/Final test score: 0.9417/0.8816/0.8436/0.8904/0.8442

Epoch: 160/1800, Average epoch time: 22.13s, Loss: 0.1506
Train/Val/Test loss: 0.1667/0.3164/0.3742
Train/Val/Test/Best val/Final test score: 0.9528/0.8926/0.8503/0.8926/0.8503

Epoch: 180/1800, Average epoch time: 22.17s, Loss: 0.1458
Train/Val/Test loss: 0.1758/0.3348/0.3732
Train/Val/Test/Best val/Final test score: 0.9493/0.8862/0.8527/0.8926/0.8503

Epoch: 200/1800, Average epoch time: 22.18s, Loss: 0.1405
Train/Val/Test loss: 0.1393/0.2991/0.3965
Train/Val/Test/Best val/Final test score: 0.9627/0.9046/0.8610/0.9046/0.8610

preprocess
Graph(num_nodes=132534, num_edges=79122504,
      ndata_schemes={'species': Scheme(shape=(1,), dtype=torch.int64), 'labels': Scheme(shape=(112,), dtype=torch.int64), 'feat': Scheme(shape=(8,), dtype=torch.float32), 'train_labels_onehot': Scheme(shape=(112,), dtype=torch.int64), 'deg': Scheme(shape=(), dtype=torch.float32)}
      edata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32)})
Epoch: 220/1800, Average epoch time: 22.20s, Loss: 0.1371
Train/Val/Test loss: 0.1323/0.2797/0.3792
Train/Val/Test/Best val/Final test score: 0.9659/0.9108/0.8646/0.9108/0.8646

Epoch: 240/1800, Average epoch time: 22.15s, Loss: 0.1343
Train/Val/Test loss: 0.1687/0.3550/0.4193
Train/Val/Test/Best val/Final test score: 0.9571/0.8908/0.8457/0.9108/0.8646

Epoch: 260/1800, Average epoch time: 22.09s, Loss: 0.1306
Train/Val/Test loss: 0.1284/0.3117/0.4356
Train/Val/Test/Best val/Final test score: 0.9697/0.9092/0.8633/0.9175/0.8679

Epoch: 280/1800, Average epoch time: 22.11s, Loss: 0.1279
Train/Val/Test loss: 0.1075/0.2706/0.3890
Train/Val/Test/Best val/Final test score: 0.9751/0.9196/0.8675/0.9196/0.8675

Epoch: 300/1800, Average epoch time: 22.14s, Loss: 0.1249
Train/Val/Test loss: 0.1199/0.2910/0.4409
Train/Val/Test/Best val/Final test score: 0.9720/0.9135/0.8600/0.9197/0.8707

Epoch: 320/1800, Average epoch time: 22.13s, Loss: 0.1217
Train/Val/Test loss: 0.1212/0.3115/0.4015
Train/Val/Test/Best val/Final test score: 0.9722/0.9054/0.8625/0.9197/0.8707

Epoch: 340/1800, Average epoch time: 22.11s, Loss: 0.1197
Train/Val/Test loss: 0.1178/0.2910/0.4284
Train/Val/Test/Best val/Final test score: 0.9733/0.9131/0.8695/0.9209/0.8695

Epoch: 360/1800, Average epoch time: 22.10s, Loss: 0.1175
Train/Val/Test loss: 0.0951/0.2732/0.4763
Train/Val/Test/Best val/Final test score: 0.9804/0.9256/0.8744/0.9256/0.8744

Epoch: 380/1800, Average epoch time: 22.10s, Loss: 0.1158
Train/Val/Test loss: 0.0941/0.2684/0.4391
Train/Val/Test/Best val/Final test score: 0.9807/0.9267/0.8756/0.9267/0.8756

Epoch: 400/1800, Average epoch time: 22.11s, Loss: 0.1135
Train/Val/Test loss: 0.1236/0.3199/0.4430
Train/Val/Test/Best val/Final test score: 0.9739/0.9070/0.8637/0.9267/0.8756

preprocess
Graph(num_nodes=132534, num_edges=79122504,
      ndata_schemes={'species': Scheme(shape=(1,), dtype=torch.int64), 'labels': Scheme(shape=(112,), dtype=torch.int64), 'feat': Scheme(shape=(8,), dtype=torch.float32), 'train_labels_onehot': Scheme(shape=(112,), dtype=torch.int64), 'deg': Scheme(shape=(), dtype=torch.float32)}
      edata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32)})
Epoch: 420/1800, Average epoch time: 21.98s, Loss: 0.1116
Train/Val/Test loss: 0.0878/0.2636/0.4256
Train/Val/Test/Best val/Final test score: 0.9828/0.9277/0.8747/0.9277/0.8747

Epoch: 440/1800, Average epoch time: 22.03s, Loss: 0.1098
Train/Val/Test loss: 0.0896/0.2772/0.4694
Train/Val/Test/Best val/Final test score: 0.9828/0.9265/0.8752/0.9277/0.8747

Epoch: 460/1800, Average epoch time: 22.10s, Loss: 0.1092
Train/Val/Test loss: 0.0897/0.2758/0.4811
Train/Val/Test/Best val/Final test score: 0.9826/0.9261/0.8752/0.9277/0.8747

Epoch: 480/1800, Average epoch time: 22.17s, Loss: 0.1070
Train/Val/Test loss: 0.0851/0.2668/0.4817
Train/Val/Test/Best val/Final test score: 0.9841/0.9296/0.8766/0.9296/0.8766

Epoch: 500/1800, Average epoch time: 22.18s, Loss: 0.1057
Train/Val/Test loss: 0.0833/0.2679/0.4862
Train/Val/Test/Best val/Final test score: 0.9848/0.9307/0.8771/0.9307/0.8771

Epoch: 520/1800, Average epoch time: 22.17s, Loss: 0.1045
Train/Val/Test loss: 0.0823/0.2778/0.5031
Train/Val/Test/Best val/Final test score: 0.9852/0.9294/0.8785/0.9307/0.8771

Epoch: 540/1800, Average epoch time: 22.16s, Loss: 0.1029
Train/Val/Test loss: 0.0786/0.2726/0.5175
Train/Val/Test/Best val/Final test score: 0.9862/0.9319/0.8787/0.9319/0.8787

Epoch: 560/1800, Average epoch time: 22.18s, Loss: 0.1013
Train/Val/Test loss: 0.0810/0.2787/0.5251
Train/Val/Test/Best val/Final test score: 0.9857/0.9298/0.8764/0.9319/0.8787

Epoch   576: reducing learning rate of group 0 to 2.2500e-03.
Epoch: 580/1800, Average epoch time: 22.20s, Loss: 0.0985
Train/Val/Test loss: 0.0756/0.2692/0.4858
Train/Val/Test/Best val/Final test score: 0.9871/0.9316/0.8738/0.9319/0.8787

Epoch: 600/1800, Average epoch time: 22.19s, Loss: 0.0964
Train/Val/Test loss: 0.0768/0.2807/0.5708
Train/Val/Test/Best val/Final test score: 0.9871/0.9311/0.8784/0.9339/0.8819

preprocess
Graph(num_nodes=132534, num_edges=79122504,
      ndata_schemes={'species': Scheme(shape=(1,), dtype=torch.int64), 'labels': Scheme(shape=(112,), dtype=torch.int64), 'feat': Scheme(shape=(8,), dtype=torch.float32), 'train_labels_onehot': Scheme(shape=(112,), dtype=torch.int64), 'deg': Scheme(shape=(), dtype=torch.float32)}
      edata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32)})
Epoch: 620/1800, Average epoch time: 22.11s, Loss: 0.0954
Train/Val/Test loss: 0.0762/0.2739/0.5654
Train/Val/Test/Best val/Final test score: 0.9872/0.9324/0.8777/0.9346/0.8787

Epoch: 640/1800, Average epoch time: 22.14s, Loss: 0.0945
Train/Val/Test loss: 0.0715/0.2799/0.5139
Train/Val/Test/Best val/Final test score: 0.9882/0.9320/0.8776/0.9346/0.8787

Epoch: 660/1800, Average epoch time: 22.18s, Loss: 0.0935
Train/Val/Test loss: 0.0703/0.2749/0.5310
Train/Val/Test/Best val/Final test score: 0.9887/0.9334/0.8779/0.9346/0.8787

Epoch   666: reducing learning rate of group 0 to 1.6875e-03.
Epoch: 680/1800, Average epoch time: 22.17s, Loss: 0.0906
Train/Val/Test loss: 0.0692/0.2779/0.5779
Train/Val/Test/Best val/Final test score: 0.9892/0.9343/0.8787/0.9355/0.8832

Epoch: 700/1800, Average epoch time: 22.18s, Loss: 0.0895
Train/Val/Test loss: 0.0676/0.2778/0.5730
Train/Val/Test/Best val/Final test score: 0.9895/0.9347/0.8805/0.9359/0.8802

Epoch: 720/1800, Average epoch time: 22.13s, Loss: 0.0889
Train/Val/Test loss: 0.0657/0.2808/0.5816
Train/Val/Test/Best val/Final test score: 0.9900/0.9358/0.8807/0.9359/0.8802

Epoch: 740/1800, Average epoch time: 22.11s, Loss: 0.0888
Train/Val/Test loss: 0.0667/0.2869/0.5873
Train/Val/Test/Best val/Final test score: 0.9898/0.9339/0.8764/0.9359/0.8802

Epoch   741: reducing learning rate of group 0 to 1.2656e-03.
Epoch: 760/1800, Average epoch time: 22.09s, Loss: 0.0863
Train/Val/Test loss: 0.0643/0.2743/0.6014
Train/Val/Test/Best val/Final test score: 0.9905/0.9372/0.8805/0.9372/0.8805

Epoch: 780/1800, Average epoch time: 22.08s, Loss: 0.0859
Train/Val/Test loss: 0.0640/0.2772/0.6345
Train/Val/Test/Best val/Final test score: 0.9906/0.9380/0.8802/0.9380/0.8802

Epoch: 800/1800, Average epoch time: 22.08s, Loss: 0.0848
Train/Val/Test loss: 0.0632/0.2889/0.6061
Train/Val/Test/Best val/Final test score: 0.9907/0.9353/0.8794/0.9380/0.8802

preprocess
Graph(num_nodes=132534, num_edges=79122504,
      ndata_schemes={'species': Scheme(shape=(1,), dtype=torch.int64), 'labels': Scheme(shape=(112,), dtype=torch.int64), 'feat': Scheme(shape=(8,), dtype=torch.float32), 'train_labels_onehot': Scheme(shape=(112,), dtype=torch.int64), 'deg': Scheme(shape=(), dtype=torch.float32)}
      edata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32)})
Epoch: 820/1800, Average epoch time: 22.05s, Loss: 0.0846
Train/Val/Test loss: 0.0631/0.2862/0.6078
Train/Val/Test/Best val/Final test score: 0.9907/0.9366/0.8807/0.9382/0.8806

Epoch: 840/1800, Average epoch time: 22.00s, Loss: 0.0841
Train/Val/Test loss: 0.0620/0.2849/0.6383
Train/Val/Test/Best val/Final test score: 0.9909/0.9366/0.8799/0.9382/0.8806

Epoch: 860/1800, Average epoch time: 21.98s, Loss: 0.0829
Train/Val/Test loss: 0.0614/0.2808/0.6169
Train/Val/Test/Best val/Final test score: 0.9912/0.9374/0.8818/0.9382/0.8806

Epoch   861: reducing learning rate of group 0 to 9.4922e-04.
Epoch: 880/1800, Average epoch time: 22.02s, Loss: 0.0816
Train/Val/Test loss: 0.0600/0.2896/0.6192
Train/Val/Test/Best val/Final test score: 0.9914/0.9362/0.8783/0.9382/0.8806

Epoch: 900/1800, Average epoch time: 22.04s, Loss: 0.0812
Train/Val/Test loss: 0.0596/0.2906/0.6373
Train/Val/Test/Best val/Final test score: 0.9916/0.9373/0.8823/0.9382/0.8806

Epoch: 920/1800, Average epoch time: 22.03s, Loss: 0.0804
Train/Val/Test loss: 0.0602/0.2969/0.6503
Train/Val/Test/Best val/Final test score: 0.9916/0.9354/0.8805/0.9394/0.8816

Epoch: 940/1800, Average epoch time: 22.03s, Loss: 0.0803
Train/Val/Test loss: 0.0582/0.2897/0.6123
Train/Val/Test/Best val/Final test score: 0.9919/0.9364/0.8778/0.9394/0.8816

Epoch   956: reducing learning rate of group 0 to 7.1191e-04.
Epoch: 960/1800, Average epoch time: 22.04s, Loss: 0.0795
Train/Val/Test loss: 0.0576/0.2910/0.6472
Train/Val/Test/Best val/Final test score: 0.9921/0.9379/0.8802/0.9394/0.8816

Epoch: 980/1800, Average epoch time: 22.04s, Loss: 0.0784
Train/Val/Test loss: 0.0578/0.2931/0.6853
Train/Val/Test/Best val/Final test score: 0.9920/0.9383/0.8814/0.9394/0.8816

Epoch: 1000/1800, Average epoch time: 22.02s, Loss: 0.0783
Train/Val/Test loss: 0.0569/0.2942/0.6380
Train/Val/Test/Best val/Final test score: 0.9923/0.9380/0.8809/0.9394/0.8816

Epoch  1007: reducing learning rate of group 0 to 5.3394e-04.
Epoch: 1020/1800, Average epoch time: 22.03s, Loss: 0.0773
Train/Val/Test loss: 0.0557/0.2940/0.6630
Train/Val/Test/Best val/Final test score: 0.9925/0.9383/0.8816/0.9394/0.8816

Epoch: 1040/1800, Average epoch time: 22.03s, Loss: 0.0773
Train/Val/Test loss: 0.0555/0.2936/0.6787
Train/Val/Test/Best val/Final test score: 0.9926/0.9392/0.8819/0.9394/0.8816

Epoch  1058: reducing learning rate of group 0 to 4.0045e-04.
Epoch: 1060/1800, Average epoch time: 22.01s, Loss: 0.0765
Train/Val/Test loss: 0.0559/0.2964/0.6869
Train/Val/Test/Best val/Final test score: 0.9926/0.9378/0.8806/0.9394/0.8816

Epoch: 1080/1800, Average epoch time: 22.00s, Loss: 0.0763
Train/Val/Test loss: 0.0548/0.2980/0.6774
Train/Val/Test/Best val/Final test score: 0.9928/0.9389/0.8804/0.9395/0.8825

Epoch: 1100/1800, Average epoch time: 22.02s, Loss: 0.0757
Train/Val/Test loss: 0.0544/0.2993/0.6832
Train/Val/Test/Best val/Final test score: 0.9928/0.9385/0.8801/0.9395/0.8825

Epoch  1109: reducing learning rate of group 0 to 3.0034e-04.
Epoch: 1120/1800, Average epoch time: 22.04s, Loss: 0.0755
Train/Val/Test loss: 0.0540/0.2995/0.6951
Train/Val/Test/Best val/Final test score: 0.9929/0.9387/0.8813/0.9396/0.8819

Epoch: 1140/1800, Average epoch time: 22.03s, Loss: 0.0750
Train/Val/Test loss: 0.0539/0.2986/0.7074
Train/Val/Test/Best val/Final test score: 0.9930/0.9401/0.8823/0.9401/0.8823

Epoch: 1160/1800, Average epoch time: 22.03s, Loss: 0.0750
Train/Val/Test loss: 0.0532/0.3014/0.6842
Train/Val/Test/Best val/Final test score: 0.9931/0.9386/0.8805/0.9401/0.8823

Epoch: 1180/1800, Average epoch time: 22.03s, Loss: 0.0746
Train/Val/Test loss: 0.0533/0.3016/0.7029
Train/Val/Test/Best val/Final test score: 0.9931/0.9392/0.8807/0.9401/0.8823

Epoch  1191: reducing learning rate of group 0 to 2.2525e-04.
Epoch: 1200/1800, Average epoch time: 22.03s, Loss: 0.0742
Train/Val/Test loss: 0.0532/0.3010/0.7156
Train/Val/Test/Best val/Final test score: 0.9932/0.9394/0.8807/0.9401/0.8823

Epoch: 1220/1800, Average epoch time: 22.03s, Loss: 0.0739
Train/Val/Test loss: 0.0528/0.3014/0.6956
Train/Val/Test/Best val/Final test score: 0.9932/0.9392/0.8812/0.9401/0.8823

Epoch: 1240/1800, Average epoch time: 22.03s, Loss: 0.0738
Train/Val/Test loss: 0.0527/0.3019/0.7018
Train/Val/Test/Best val/Final test score: 0.9933/0.9390/0.8803/0.9401/0.8823

Epoch  1242: reducing learning rate of group 0 to 1.6894e-04.
Epoch: 1260/1800, Average epoch time: 22.03s, Loss: 0.0736
Train/Val/Test loss: 0.0527/0.3025/0.7070
Train/Val/Test/Best val/Final test score: 0.9932/0.9395/0.8808/0.9401/0.8823

Epoch: 1280/1800, Average epoch time: 22.03s, Loss: 0.0733
Train/Val/Test loss: 0.0526/0.3025/0.7031
Train/Val/Test/Best val/Final test score: 0.9933/0.9391/0.8813/0.9401/0.8823

Epoch  1293: reducing learning rate of group 0 to 1.2671e-04.
Epoch: 1300/1800, Average epoch time: 22.03s, Loss: 0.0732
Train/Val/Test loss: 0.0527/0.3037/0.7226
Train/Val/Test/Best val/Final test score: 0.9933/0.9395/0.8802/0.9401/0.8823

Epoch: 1320/1800, Average epoch time: 22.04s, Loss: 0.0731
Train/Val/Test loss: 0.0521/0.3021/0.7132
Train/Val/Test/Best val/Final test score: 0.9934/0.9399/0.8808/0.9401/0.8823

Epoch: 1340/1800, Average epoch time: 22.04s, Loss: 0.0733
Train/Val/Test loss: 0.0523/0.3048/0.7120
Train/Val/Test/Best val/Final test score: 0.9933/0.9393/0.8799/0.9401/0.8823

Epoch  1344: reducing learning rate of group 0 to 9.5029e-05.
Epoch: 1360/1800, Average epoch time: 22.04s, Loss: 0.0729
Train/Val/Test loss: 0.0523/0.3025/0.7226
Train/Val/Test/Best val/Final test score: 0.9934/0.9400/0.8812/0.9401/0.8823

Epoch: 1380/1800, Average epoch time: 22.04s, Loss: 0.0729
Train/Val/Test loss: 0.0523/0.3017/0.7198
Train/Val/Test/Best val/Final test score: 0.9934/0.9399/0.8815/0.9401/0.8823

Epoch  1395: reducing learning rate of group 0 to 7.1272e-05.
Epoch: 1400/1800, Average epoch time: 22.03s, Loss: 0.0729
Train/Val/Test loss: 0.0522/0.3031/0.7240
Train/Val/Test/Best val/Final test score: 0.9934/0.9395/0.8811/0.9401/0.8823

Epoch: 1420/1800, Average epoch time: 22.02s, Loss: 0.0725
Train/Val/Test loss: 0.0517/0.3043/0.7174
Train/Val/Test/Best val/Final test score: 0.9934/0.9395/0.8816/0.9401/0.8823

Epoch: 1440/1800, Average epoch time: 22.02s, Loss: 0.0726
Train/Val/Test loss: 0.0520/0.3041/0.7178
Train/Val/Test/Best val/Final test score: 0.9934/0.9394/0.8816/0.9401/0.8823

Epoch  1446: reducing learning rate of group 0 to 5.3454e-05.
Epoch: 1460/1800, Average epoch time: 22.00s, Loss: 0.0725
Train/Val/Test loss: 0.0521/0.3056/0.7233
Train/Val/Test/Best val/Final test score: 0.9934/0.9388/0.8819/0.9401/0.8823

Epoch: 1480/1800, Average epoch time: 21.99s, Loss: 0.0725
Train/Val/Test loss: 0.0519/0.3058/0.7262
Train/Val/Test/Best val/Final test score: 0.9934/0.9396/0.8824/0.9401/0.8823

Epoch  1497: reducing learning rate of group 0 to 4.0090e-05.
Epoch: 1500/1800, Average epoch time: 21.96s, Loss: 0.0725
Train/Val/Test loss: 0.0518/0.3066/0.7254
Train/Val/Test/Best val/Final test score: 0.9935/0.9392/0.8816/0.9401/0.8823

Traceback (most recent call last):
  File "/home/liweikai/gat_bot_ngnn/gat_bot_ngnn.py", line 593, in <module>
    main()
  File "/home/liweikai/gat_bot_ngnn/gat_bot_ngnn.py", line 578, in main
    val_score, test_score = run(args, graph, labels, train_idx, val_idx, test_idx, evaluator, i + 1)
  File "/home/liweikai/gat_bot_ngnn/gat_bot_ngnn.py", line 440, in run
    val_score, best_val_score, new_final_test_score, new_final_pred) = run_epochs(args, graph, \
  File "/home/liweikai/gat_bot_ngnn/gat_bot_ngnn.py", line 288, in run_epochs
    loss = train(args, model, train_dataloader, labels, train_idx, criterion, optimizer, evaluator_wrapper)
  File "/home/liweikai/gat_bot_ngnn/gat_bot_ngnn.py", line 150, in train
    pred = model(subgraphs)
  File "/home/cenyukuo/anaconda3/envs/gat_bot_ngnn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/liweikai/gat_bot_ngnn/models.py", line 367, in forward
    efeat = subgraphs[i].edata["feat"]
  File "/home/cenyukuo/anaconda3/envs/gat_bot_ngnn/lib/python3.9/site-packages/dgl/view.py", line 181, in __getitem__
    return self._graph._get_e_repr(self._etid, self._edges)[key]
  File "/home/cenyukuo/anaconda3/envs/gat_bot_ngnn/lib/python3.9/site-packages/dgl/heterograph.py", line 4233, in _get_e_repr
    return dict(self._edge_frames[etid])
  File "/home/cenyukuo/anaconda3/envs/gat_bot_ngnn/lib/python3.9/site-packages/dgl/frame.py", line 393, in __getitem__
    return self._columns[name].data
  File "/home/cenyukuo/anaconda3/envs/gat_bot_ngnn/lib/python3.9/site-packages/dgl/frame.py", line 121, in data
    self.index = F.copy_to(self.index, F.context(self.storage), **kwargs)
  File "/home/cenyukuo/anaconda3/envs/gat_bot_ngnn/lib/python3.9/site-packages/dgl/backend/pytorch/tensor.py", line 119, in copy_to
    return input.cuda(**kwargs)
KeyboardInterrupt
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: \ 0.024 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.024 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: / 0.024 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: - 0.024 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: \ 0.024 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.024 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: / 0.024 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: - 0.024 MB of 0.024 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:   best_val_score ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: final_test_score ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:        test_loss ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:       test_score ‚ñÑ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:       train_loss ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      train_score ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:         val_loss ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:        val_score ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   best_val_score 0.94015
wandb: final_test_score 0.88234
wandb:        test_loss 0.72148
wandb:       test_score 0.88097
wandb:       train_loss 0.05174
wandb:      train_score 0.99348
wandb:         val_loss 0.30504
wandb:        val_score 0.93938
wandb: 
wandb: Synced dutiful-shadow-222: https://wandb.ai/billywkli/GAT_BOT_NGNN_proteins/runs/1y1auh32
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220604_071703-1y1auh32/logs
