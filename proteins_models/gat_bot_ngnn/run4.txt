Using backend: pytorch
wandb: Currently logged in as: billywkli. Use `wandb login --relogin` to force relogin
device cuda:0
Loading data
Graph(num_nodes=132534, num_edges=79122504,
      ndata_schemes={'species': Scheme(shape=(1,), dtype=torch.int64), 'labels': Scheme(shape=(112,), dtype=torch.int64)}
      edata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32)})
wandb: wandb version 0.12.17 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /home/liweikai/gat_bot_ngnn/wandb/run-20220604_071532-1s623lsh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-serenity-218
wandb: ‚≠êÔ∏è View project at https://wandb.ai/billywkli/GAT_BOT_NGNN_proteins
wandb: üöÄ View run at https://wandb.ai/billywkli/GAT_BOT_NGNN_proteins/runs/1s623lsh
Running 0
278744028 params
preprocess
Graph(num_nodes=132534, num_edges=79122504,
      ndata_schemes={'species': Scheme(shape=(1,), dtype=torch.int64), 'labels': Scheme(shape=(112,), dtype=torch.int64), 'feat': Scheme(shape=(8,), dtype=torch.float32), 'train_labels_onehot': Scheme(shape=(112,), dtype=torch.int64), 'deg': Scheme(shape=(), dtype=torch.float32)}
      edata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32)})
Epoch: 20/1800, Average epoch time: 22.80s, Loss: 0.2294
Train/Val/Test loss: 0.2917/0.4694/0.4819
Train/Val/Test/Best val/Final test score: 0.8604/0.8110/0.7529/0.8123/0.7548

Epoch: 40/1800, Average epoch time: 22.84s, Loss: 0.2037
Train/Val/Test loss: 0.2386/0.3437/0.3066
Train/Val/Test/Best val/Final test score: 0.8988/0.8500/0.8091/0.8500/0.8091

Epoch: 60/1800, Average epoch time: 22.89s, Loss: 0.1916
Train/Val/Test loss: 0.2648/0.4099/0.4473
Train/Val/Test/Best val/Final test score: 0.9034/0.8468/0.8110/0.8683/0.8135

Epoch: 80/1800, Average epoch time: 22.86s, Loss: 0.1832
Train/Val/Test loss: 0.2013/0.3187/0.3544
Train/Val/Test/Best val/Final test score: 0.9291/0.8799/0.8384/0.8801/0.8279

Epoch: 100/1800, Average epoch time: 22.82s, Loss: 0.1753
Train/Val/Test loss: 0.1623/0.2830/0.2939
Train/Val/Test/Best val/Final test score: 0.9455/0.8932/0.8487/0.8932/0.8487

Epoch: 120/1800, Average epoch time: 22.79s, Loss: 0.1681
Train/Val/Test loss: 0.2125/0.3810/0.4074
Train/Val/Test/Best val/Final test score: 0.9320/0.8636/0.8249/0.8932/0.8487

Epoch: 140/1800, Average epoch time: 22.81s, Loss: 0.1620
Train/Val/Test loss: 0.1534/0.3092/0.3428
Train/Val/Test/Best val/Final test score: 0.9536/0.8933/0.8466/0.8970/0.8528

Epoch: 160/1800, Average epoch time: 22.79s, Loss: 0.1570
Train/Val/Test loss: 0.1638/0.3206/0.3849
Train/Val/Test/Best val/Final test score: 0.9521/0.8905/0.8447/0.9024/0.8575

Epoch: 180/1800, Average epoch time: 22.79s, Loss: 0.1504
Train/Val/Test loss: 0.1429/0.2917/0.3645
Train/Val/Test/Best val/Final test score: 0.9604/0.9025/0.8578/0.9078/0.8612

Epoch: 200/1800, Average epoch time: 22.79s, Loss: 0.1477
Train/Val/Test loss: 0.1308/0.2788/0.3996
Train/Val/Test/Best val/Final test score: 0.9655/0.9113/0.8652/0.9113/0.8652

preprocess
Graph(num_nodes=132534, num_edges=79122504,
      ndata_schemes={'species': Scheme(shape=(1,), dtype=torch.int64), 'labels': Scheme(shape=(112,), dtype=torch.int64), 'feat': Scheme(shape=(8,), dtype=torch.float32), 'train_labels_onehot': Scheme(shape=(112,), dtype=torch.int64), 'deg': Scheme(shape=(), dtype=torch.float32)}
      edata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32)})
Epoch: 220/1800, Average epoch time: 22.72s, Loss: 0.1420
Train/Val/Test loss: 0.1209/0.2744/0.3823
Train/Val/Test/Best val/Final test score: 0.9701/0.9139/0.8678/0.9142/0.8642

Epoch: 240/1800, Average epoch time: 22.75s, Loss: 0.1375
Train/Val/Test loss: 0.1147/0.2730/0.3993
Train/Val/Test/Best val/Final test score: 0.9725/0.9161/0.8676/0.9169/0.8679

Epoch: 260/1800, Average epoch time: 22.73s, Loss: 0.1338
Train/Val/Test loss: 0.1071/0.2682/0.3559
Train/Val/Test/Best val/Final test score: 0.9753/0.9178/0.8655/0.9198/0.8697

Epoch: 280/1800, Average epoch time: 22.70s, Loss: 0.1301
Train/Val/Test loss: 0.1098/0.2839/0.4377
Train/Val/Test/Best val/Final test score: 0.9759/0.9182/0.8711/0.9198/0.8697

Epoch: 300/1800, Average epoch time: 22.74s, Loss: 0.1270
Train/Val/Test loss: 0.1035/0.2720/0.4058
Train/Val/Test/Best val/Final test score: 0.9776/0.9221/0.8742/0.9225/0.8720

Epoch: 320/1800, Average epoch time: 22.76s, Loss: 0.1235
Train/Val/Test loss: 0.0962/0.2655/0.4087
Train/Val/Test/Best val/Final test score: 0.9800/0.9247/0.8723/0.9247/0.8723

Epoch: 340/1800, Average epoch time: 22.77s, Loss: 0.1211
Train/Val/Test loss: 0.0981/0.2772/0.4501
Train/Val/Test/Best val/Final test score: 0.9804/0.9223/0.8727/0.9247/0.8723

Epoch: 360/1800, Average epoch time: 22.77s, Loss: 0.1181
Train/Val/Test loss: 0.0920/0.2703/0.4738
Train/Val/Test/Best val/Final test score: 0.9821/0.9266/0.8776/0.9266/0.8776

Epoch: 380/1800, Average epoch time: 22.79s, Loss: 0.1152
Train/Val/Test loss: 0.0895/0.2788/0.5069
Train/Val/Test/Best val/Final test score: 0.9831/0.9263/0.8755/0.9279/0.8749

Epoch: 400/1800, Average epoch time: 22.79s, Loss: 0.1131
Train/Val/Test loss: 0.0861/0.2670/0.4732
Train/Val/Test/Best val/Final test score: 0.9840/0.9293/0.8760/0.9293/0.8760

preprocess
Graph(num_nodes=132534, num_edges=79122504,
      ndata_schemes={'species': Scheme(shape=(1,), dtype=torch.int64), 'labels': Scheme(shape=(112,), dtype=torch.int64), 'feat': Scheme(shape=(8,), dtype=torch.float32), 'train_labels_onehot': Scheme(shape=(112,), dtype=torch.int64), 'deg': Scheme(shape=(), dtype=torch.float32)}
      edata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32)})
Epoch: 420/1800, Average epoch time: 22.63s, Loss: 0.1119
Train/Val/Test loss: 0.0870/0.2721/0.4358
Train/Val/Test/Best val/Final test score: 0.9842/0.9260/0.8724/0.9303/0.8783

Epoch: 440/1800, Average epoch time: 22.65s, Loss: 0.1083
Train/Val/Test loss: 0.0831/0.2690/0.5116
Train/Val/Test/Best val/Final test score: 0.9854/0.9306/0.8744/0.9308/0.8771

Epoch: 460/1800, Average epoch time: 22.70s, Loss: 0.1077
Train/Val/Test loss: 0.0808/0.2690/0.4899
Train/Val/Test/Best val/Final test score: 0.9861/0.9309/0.8763/0.9313/0.8781

Epoch: 480/1800, Average epoch time: 22.81s, Loss: 0.1049
Train/Val/Test loss: 0.0761/0.2746/0.4897
Train/Val/Test/Best val/Final test score: 0.9871/0.9319/0.8778/0.9319/0.8778

Epoch: 500/1800, Average epoch time: 22.79s, Loss: 0.1038
Train/Val/Test loss: 0.0747/0.2662/0.4700
Train/Val/Test/Best val/Final test score: 0.9877/0.9331/0.8757/0.9331/0.8757

Epoch: 520/1800, Average epoch time: 22.79s, Loss: 0.1030
Train/Val/Test loss: 0.0736/0.2706/0.4879
Train/Val/Test/Best val/Final test score: 0.9879/0.9319/0.8773/0.9331/0.8778

Epoch: 540/1800, Average epoch time: 22.79s, Loss: 0.1002
Train/Val/Test loss: 0.0711/0.2679/0.4773
Train/Val/Test/Best val/Final test score: 0.9887/0.9325/0.8763/0.9344/0.8783

Epoch: 560/1800, Average epoch time: 22.80s, Loss: 0.1002
Train/Val/Test loss: 0.0707/0.2686/0.5209
Train/Val/Test/Best val/Final test score: 0.9890/0.9345/0.8778/0.9363/0.8802

Epoch: 580/1800, Average epoch time: 22.78s, Loss: 0.0966
Train/Val/Test loss: 0.0696/0.2734/0.5729
Train/Val/Test/Best val/Final test score: 0.9894/0.9358/0.8791/0.9363/0.8802

Epoch: 600/1800, Average epoch time: 22.80s, Loss: 0.0955
Train/Val/Test loss: 0.0671/0.2820/0.5277
Train/Val/Test/Best val/Final test score: 0.9900/0.9349/0.8782/0.9366/0.8793

preprocess
Graph(num_nodes=132534, num_edges=79122504,
      ndata_schemes={'species': Scheme(shape=(1,), dtype=torch.int64), 'labels': Scheme(shape=(112,), dtype=torch.int64), 'feat': Scheme(shape=(8,), dtype=torch.float32), 'train_labels_onehot': Scheme(shape=(112,), dtype=torch.int64), 'deg': Scheme(shape=(), dtype=torch.float32)}
      edata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32)})
Epoch: 620/1800, Average epoch time: 22.86s, Loss: 0.0941
Train/Val/Test loss: 0.0656/0.2785/0.4730
Train/Val/Test/Best val/Final test score: 0.9901/0.9330/0.8762/0.9376/0.8816

Epoch: 640/1800, Average epoch time: 22.89s, Loss: 0.0933
Train/Val/Test loss: 0.0658/0.2752/0.5015
Train/Val/Test/Best val/Final test score: 0.9903/0.9350/0.8763/0.9376/0.8816

Epoch: 660/1800, Average epoch time: 22.87s, Loss: 0.0924
Train/Val/Test loss: 0.0640/0.2821/0.5125
Train/Val/Test/Best val/Final test score: 0.9907/0.9352/0.8776/0.9379/0.8793

Epoch: 680/1800, Average epoch time: 22.85s, Loss: 0.0914
Train/Val/Test loss: 0.0635/0.2895/0.5725
Train/Val/Test/Best val/Final test score: 0.9910/0.9361/0.8810/0.9379/0.8797

Epoch: 700/1800, Average epoch time: 22.83s, Loss: 0.0896
Train/Val/Test loss: 0.0624/0.2830/0.5690
Train/Val/Test/Best val/Final test score: 0.9912/0.9363/0.8766/0.9382/0.8788

Epoch: 720/1800, Average epoch time: 22.82s, Loss: 0.0877
Train/Val/Test loss: 0.0609/0.2794/0.5789
Train/Val/Test/Best val/Final test score: 0.9917/0.9381/0.8794/0.9383/0.8809

Epoch: 740/1800, Average epoch time: 22.81s, Loss: 0.0876
Train/Val/Test loss: 0.0599/0.2772/0.5435
Train/Val/Test/Best val/Final test score: 0.9919/0.9369/0.8779/0.9390/0.8828

Epoch: 760/1800, Average epoch time: 22.79s, Loss: 0.0862
Train/Val/Test loss: 0.0593/0.2734/0.5327
Train/Val/Test/Best val/Final test score: 0.9921/0.9374/0.8800/0.9400/0.8818

Epoch: 780/1800, Average epoch time: 22.79s, Loss: 0.0858
Train/Val/Test loss: 0.0591/0.2711/0.6107
Train/Val/Test/Best val/Final test score: 0.9922/0.9409/0.8817/0.9409/0.8817

Epoch: 800/1800, Average epoch time: 22.80s, Loss: 0.0855
Train/Val/Test loss: 0.0592/0.2723/0.6180
Train/Val/Test/Best val/Final test score: 0.9923/0.9400/0.8789/0.9409/0.8817

preprocess
Graph(num_nodes=132534, num_edges=79122504,
      ndata_schemes={'species': Scheme(shape=(1,), dtype=torch.int64), 'labels': Scheme(shape=(112,), dtype=torch.int64), 'feat': Scheme(shape=(8,), dtype=torch.float32), 'train_labels_onehot': Scheme(shape=(112,), dtype=torch.int64), 'deg': Scheme(shape=(), dtype=torch.float32)}
      edata_schemes={'feat': Scheme(shape=(8,), dtype=torch.float32)})
Epoch: 820/1800, Average epoch time: 22.70s, Loss: 0.0831
Train/Val/Test loss: 0.0580/0.2808/0.6412
Train/Val/Test/Best val/Final test score: 0.9925/0.9396/0.8824/0.9410/0.8805

Epoch: 840/1800, Average epoch time: 22.69s, Loss: 0.0830
Train/Val/Test loss: 0.0561/0.2778/0.5808
Train/Val/Test/Best val/Final test score: 0.9928/0.9386/0.8779/0.9410/0.8805

Epoch: 860/1800, Average epoch time: 22.73s, Loss: 0.0815
Train/Val/Test loss: 0.0558/0.2887/0.6313
Train/Val/Test/Best val/Final test score: 0.9929/0.9394/0.8809/0.9415/0.8803

Epoch: 880/1800, Average epoch time: 22.75s, Loss: 0.0809
Train/Val/Test loss: 0.0539/0.2839/0.5877
Train/Val/Test/Best val/Final test score: 0.9933/0.9404/0.8801/0.9415/0.8803

Epoch: 900/1800, Average epoch time: 22.76s, Loss: 0.0801
Train/Val/Test loss: 0.0553/0.2775/0.6639
Train/Val/Test/Best val/Final test score: 0.9931/0.9416/0.8815/0.9425/0.8840

Epoch: 920/1800, Average epoch time: 22.78s, Loss: 0.0795
Train/Val/Test loss: 0.0542/0.2774/0.6526
Train/Val/Test/Best val/Final test score: 0.9934/0.9433/0.8827/0.9433/0.8827

Epoch: 940/1800, Average epoch time: 22.79s, Loss: 0.0791
Train/Val/Test loss: 0.0560/0.2889/0.7076
Train/Val/Test/Best val/Final test score: 0.9931/0.9403/0.8812/0.9433/0.8827

Epoch: 960/1800, Average epoch time: 22.81s, Loss: 0.0778
Train/Val/Test loss: 0.0528/0.2862/0.6478
Train/Val/Test/Best val/Final test score: 0.9936/0.9414/0.8797/0.9433/0.8827

Epoch   971: reducing learning rate of group 0 to 2.2500e-03.
Epoch: 980/1800, Average epoch time: 22.80s, Loss: 0.0743
Train/Val/Test loss: 0.0507/0.2932/0.6955
Train/Val/Test/Best val/Final test score: 0.9941/0.9425/0.8807/0.9433/0.8827

Epoch: 1000/1800, Average epoch time: 22.78s, Loss: 0.0724
Train/Val/Test loss: 0.0496/0.2842/0.6605
Train/Val/Test/Best val/Final test score: 0.9945/0.9436/0.8835/0.9436/0.8835

Epoch: 1020/1800, Average epoch time: 22.79s, Loss: 0.0717
Train/Val/Test loss: 0.0481/0.2872/0.6523
Train/Val/Test/Best val/Final test score: 0.9946/0.9423/0.8815/0.9440/0.8819

Epoch: 1040/1800, Average epoch time: 22.80s, Loss: 0.0713
Train/Val/Test loss: 0.0485/0.2889/0.6187
Train/Val/Test/Best val/Final test score: 0.9946/0.9412/0.8809/0.9440/0.8819

Epoch: 1060/1800, Average epoch time: 22.80s, Loss: 0.0709
Train/Val/Test loss: 0.0477/0.2963/0.7141
Train/Val/Test/Best val/Final test score: 0.9948/0.9434/0.8851/0.9441/0.8829

Epoch  1061: reducing learning rate of group 0 to 1.6875e-03.
Epoch: 1080/1800, Average epoch time: 22.82s, Loss: 0.0682
Train/Val/Test loss: 0.0459/0.2948/0.6785
Train/Val/Test/Best val/Final test score: 0.9951/0.9438/0.8818/0.9441/0.8846

Epoch: 1100/1800, Average epoch time: 22.82s, Loss: 0.0671
Train/Val/Test loss: 0.0454/0.3037/0.7631
Train/Val/Test/Best val/Final test score: 0.9952/0.9451/0.8824/0.9454/0.8847

Epoch: 1120/1800, Average epoch time: 22.82s, Loss: 0.0667
Train/Val/Test loss: 0.0456/0.3069/0.7669
Train/Val/Test/Best val/Final test score: 0.9952/0.9446/0.8845/0.9454/0.8847

Epoch: 1140/1800, Average epoch time: 22.83s, Loss: 0.0659
Train/Val/Test loss: 0.0439/0.2981/0.7021
Train/Val/Test/Best val/Final test score: 0.9954/0.9438/0.8822/0.9454/0.8847

Epoch  1146: reducing learning rate of group 0 to 1.2656e-03.
Epoch: 1160/1800, Average epoch time: 22.84s, Loss: 0.0644
Train/Val/Test loss: 0.0424/0.3020/0.7394
Train/Val/Test/Best val/Final test score: 0.9957/0.9458/0.8822/0.9458/0.8822

Epoch: 1180/1800, Average epoch time: 22.83s, Loss: 0.0635
Train/Val/Test loss: 0.0428/0.3147/0.7912
Train/Val/Test/Best val/Final test score: 0.9957/0.9453/0.8848/0.9458/0.8852

Epoch: 1200/1800, Average epoch time: 22.85s, Loss: 0.0628
Train/Val/Test loss: 0.0419/0.3094/0.7596
Train/Val/Test/Best val/Final test score: 0.9959/0.9451/0.8837/0.9458/0.8852

Epoch  1211: reducing learning rate of group 0 to 9.4922e-04.
Epoch: 1220/1800, Average epoch time: 22.85s, Loss: 0.0616
Train/Val/Test loss: 0.0412/0.3163/0.7709
Train/Val/Test/Best val/Final test score: 0.9960/0.9456/0.8851/0.9458/0.8852

Epoch: 1240/1800, Average epoch time: 22.86s, Loss: 0.0607
Train/Val/Test loss: 0.0405/0.3159/0.7813
Train/Val/Test/Best val/Final test score: 0.9961/0.9460/0.8854/0.9460/0.8828

Epoch: 1260/1800, Average epoch time: 22.85s, Loss: 0.0604
Train/Val/Test loss: 0.0398/0.3143/0.7825
Train/Val/Test/Best val/Final test score: 0.9962/0.9458/0.8841/0.9470/0.8848

Epoch: 1280/1800, Average epoch time: 22.84s, Loss: 0.0602
Train/Val/Test loss: 0.0398/0.3096/0.7436
Train/Val/Test/Best val/Final test score: 0.9962/0.9448/0.8832/0.9470/0.8848

Epoch: 1300/1800, Average epoch time: 22.84s, Loss: 0.0602
Train/Val/Test loss: 0.0398/0.3071/0.7977
Train/Val/Test/Best val/Final test score: 0.9963/0.9469/0.8842/0.9472/0.8842

Epoch: 1320/1800, Average epoch time: 22.84s, Loss: 0.0590
Train/Val/Test loss: 0.0397/0.3078/0.8033
Train/Val/Test/Best val/Final test score: 0.9963/0.9470/0.8842/0.9472/0.8842

Epoch: 1340/1800, Average epoch time: 22.83s, Loss: 0.0593
Train/Val/Test loss: 0.0391/0.3074/0.7948
Train/Val/Test/Best val/Final test score: 0.9964/0.9471/0.8840/0.9474/0.8836

Epoch: 1360/1800, Average epoch time: 22.83s, Loss: 0.0583
Train/Val/Test loss: 0.0389/0.3143/0.8076
Train/Val/Test/Best val/Final test score: 0.9964/0.9466/0.8844/0.9474/0.8836

Epoch: 1380/1800, Average epoch time: 22.81s, Loss: 0.0583
Train/Val/Test loss: 0.0384/0.3166/0.8130
Train/Val/Test/Best val/Final test score: 0.9965/0.9473/0.8844/0.9474/0.8836

Epoch  1386: reducing learning rate of group 0 to 7.1191e-04.
Epoch: 1400/1800, Average epoch time: 22.80s, Loss: 0.0575
Train/Val/Test loss: 0.0376/0.3166/0.8049
Train/Val/Test/Best val/Final test score: 0.9966/0.9467/0.8841/0.9478/0.8854

Epoch: 1420/1800, Average epoch time: 22.78s, Loss: 0.0570
Train/Val/Test loss: 0.0375/0.3215/0.8121
Train/Val/Test/Best val/Final test score: 0.9967/0.9470/0.8842/0.9478/0.8854

Epoch: 1440/1800, Average epoch time: 22.76s, Loss: 0.0563
Train/Val/Test loss: 0.0370/0.3225/0.8301
Train/Val/Test/Best val/Final test score: 0.9967/0.9470/0.8845/0.9478/0.8854

Epoch  1446: reducing learning rate of group 0 to 5.3394e-04.
Epoch: 1460/1800, Average epoch time: 22.74s, Loss: 0.0558
Train/Val/Test loss: 0.0369/0.3163/0.8356
Train/Val/Test/Best val/Final test score: 0.9968/0.9474/0.8844/0.9478/0.8854

Epoch: 1480/1800, Average epoch time: 22.71s, Loss: 0.0557
Train/Val/Test loss: 0.0365/0.3185/0.8285
Train/Val/Test/Best val/Final test score: 0.9968/0.9475/0.8843/0.9479/0.8865

Traceback (most recent call last):
  File "/home/liweikai/gat_bot_ngnn/gat_bot_ngnn.py", line 593, in <module>
    main()
  File "/home/liweikai/gat_bot_ngnn/gat_bot_ngnn.py", line 578, in main
    val_score, test_score = run(args, graph, labels, train_idx, val_idx, test_idx, evaluator, i + 1)
  File "/home/liweikai/gat_bot_ngnn/gat_bot_ngnn.py", line 440, in run
    val_score, best_val_score, new_final_test_score, new_final_pred) = run_epochs(args, graph, \
  File "/home/liweikai/gat_bot_ngnn/gat_bot_ngnn.py", line 288, in run_epochs
    loss = train(args, model, train_dataloader, labels, train_idx, criterion, optimizer, evaluator_wrapper)
  File "/home/liweikai/gat_bot_ngnn/gat_bot_ngnn.py", line 153, in train
    loss.backward()
  File "/home/cenyukuo/anaconda3/envs/gat_bot_ngnn/lib/python3.9/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/cenyukuo/anaconda3/envs/gat_bot_ngnn/lib/python3.9/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.023 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.023 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: / 0.023 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: - 0.023 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.023 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.023 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: / 0.023 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: - 0.023 MB of 0.023 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:   best_val_score ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: final_test_score ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:        test_loss ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:       test_score ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:       train_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      train_score ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:         val_loss ‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:        val_score ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:   best_val_score 0.94794
wandb: final_test_score 0.88645
wandb:        test_loss 0.82847
wandb:       test_score 0.88433
wandb:       train_loss 0.03654
wandb:      train_score 0.99681
wandb:         val_loss 0.31852
wandb:        val_score 0.9475
wandb: 
wandb: Synced fluent-serenity-218: https://wandb.ai/billywkli/GAT_BOT_NGNN_proteins/runs/1s623lsh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220604_071532-1s623lsh/logs
